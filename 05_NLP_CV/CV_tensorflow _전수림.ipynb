{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CV_tensorflow.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "EEqZri8nfnvv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce455fe1-b0c1-4aef-c8cf-16417dfff463"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensorflow version 2.3.1\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras import datasets, layers, models\n",
        "import tensorflow as tf\n",
        "# TODO: Change Models You want https://www.tensorflow.org/api_docs/python/tf/keras/applications/resnet\n",
        "from tensorflow.keras.applications.vgg19 import VGG19\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "import numpy as np\n",
        "\n",
        "print(\"Tensorflow version \" + tf.__version__)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **CIFAR 10 Datast 데이터셋 다운로드하고 준비하기**\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fzpcT5kagCDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image_input(input_images):\n",
        "  input_images = input_images.astype('float32')\n",
        "  # TODO: Change Models You want to change\n",
        "  output_ims = tf.keras.applications.vgg19.preprocess_input(input_images)\n",
        "  return output_ims"
      ],
      "metadata": {
        "id": "3EwSYhKef_gc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(training_images, training_labels) , (validation_images, validation_labels) = tf.keras.datasets.cifar10.load_data()"
      ],
      "metadata": {
        "id": "qHnJYS-dnerE"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X = preprocess_image_input(training_images)\n",
        "valid_X = preprocess_image_input(validation_images)"
      ],
      "metadata": {
        "id": "lEK1rG5CnpNp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_X.shape"
      ],
      "metadata": {
        "id": "rydYj6jEmgua",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76f6a421-4bc6-434e-96ff-4d437a24bcc5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 32, 32, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''\n",
        "Feature Extraction is performed by ResNet50 pretrained on imagenet weights. \n",
        "Input size is 224 x 224.\n",
        "'''\n",
        "def feature_extractor(inputs):\n",
        "\n",
        "  #Change Models Here too!!!\n",
        "  \n",
        "  feature_extractor = tf.keras.applications.VGG19(input_shape=(224, 224, 3),\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')(inputs)\n",
        "  return feature_extractor\n",
        "\n",
        "\n",
        "'''\n",
        "Defines final dense layers and subsequent softmax layer for classification.\n",
        "'''\n",
        "def classifier(inputs):\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(inputs)\n",
        "    x = tf.keras.layers.Flatten()(x)\n",
        "    x = tf.keras.layers.Dense(1024, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(512, activation=\"relu\")(x)\n",
        "    x = tf.keras.layers.Dense(10, activation=\"softmax\", name=\"classification\")(x)\n",
        "    return x\n",
        "\n",
        "'''\n",
        "Since input image size is (32 x 32), first upsample the image by factor of (7x7) to transform it to (224 x 224)\n",
        "Connect the feature extraction and \"classifier\" layers to build the model.\n",
        "'''\n",
        "def final_model(inputs):\n",
        "\n",
        "    resize = tf.keras.layers.UpSampling2D(size=(7,7))(inputs)\n",
        "    vgg19_feature_extractor = feature_extractor(resize)\n",
        "    classification_output = classifier(vgg19_feature_extractor)\n",
        "\n",
        "    return classification_output\n",
        "\n",
        "'''\n",
        "Define the model and compile it. \n",
        "Use Stochastic Gradient Descent as the optimizer.\n",
        "Use Sparse Categorical CrossEntropy as the loss function.\n",
        "'''\n",
        "def define_compile_model():\n",
        "  inputs = tf.keras.layers.Input(shape=(32,32,3))\n",
        "  \n",
        "  classification_output = final_model(inputs) \n",
        "  model = tf.keras.Model(inputs=inputs, outputs = classification_output)\n",
        " \n",
        "  model.compile(optimizer='Adam', \n",
        "                loss='sparse_categorical_crossentropy',\n",
        "                metrics = ['accuracy'])\n",
        "  \n",
        "  return model\n",
        "\n",
        "\n",
        "model = define_compile_model()\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "38ncn5J0nz6k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dcda0783-1fc7-46b8-a558-ce5d754d0081"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "80142336/80134624 [==============================] - 1s 0us/step\n",
            "Model: \"functional_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 32, 32, 3)]       0         \n",
            "_________________________________________________________________\n",
            "up_sampling2d (UpSampling2D) (None, 224, 224, 3)       0         \n",
            "_________________________________________________________________\n",
            "vgg19 (Functional)           (None, 7, 7, 512)         20024384  \n",
            "_________________________________________________________________\n",
            "global_average_pooling2d (Gl (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "classification (Dense)       (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 21,079,626\n",
            "Trainable params: 21,079,626\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 3\n",
        "history = model.fit(train_X, training_labels, epochs=EPOCHS, validation_data = (valid_X, validation_labels), batch_size=64)"
      ],
      "metadata": {
        "id": "mbrS9NHzhUSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf5d1065-c479-46c3-deec-b46eb5016663"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/3\n",
            "  2/782 [..............................] - ETA: 3:00 - loss: 9.8342 - accuracy: 0.0703WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.1331s vs `on_train_batch_end` time: 0.3183s). Check your callbacks.\n",
            "782/782 [==============================] - 374s 478ms/step - loss: 2.0454 - accuracy: 0.2742 - val_loss: 1.6945 - val_accuracy: 0.3696\n",
            "Epoch 2/3\n",
            "782/782 [==============================] - 373s 477ms/step - loss: 1.5920 - accuracy: 0.4149 - val_loss: 1.5073 - val_accuracy: 0.4505\n",
            "Epoch 3/3\n",
            "782/782 [==============================] - 373s 477ms/step - loss: 1.4048 - accuracy: 0.4890 - val_loss: 1.3763 - val_accuracy: 0.5073\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss, accuracy = model.evaluate(valid_X, validation_labels, batch_size=64)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "v27aJhqvjrft",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd59b987-b21d-4847-a593-2cdb641dd30e"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "157/157 [==============================] - 21s 131ms/step - loss: 1.3763 - accuracy: 0.5073\n"
          ]
        }
      ]
    }
  ]
}